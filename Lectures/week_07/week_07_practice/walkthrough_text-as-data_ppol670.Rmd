---
title: "PPOL670 | Introduction to Data Science"
subtitle: "Strings and Text-as-Data Walkthrough"
output: html_document
---

```{r include=F, paged.print=FALSE}
knitr::opts_chunk$set(warning = F,error = F,message = F)
require(tidyverse)
require(tidytext)
require(topicmodels)
```


# String Manipulations


## Example 1

We'll use what we know of manipulation to clean the following string.

```{r}
dirty_string = "22Clean 5674.5this $%&*_@string!"
dirty_string
```


Remove the numbers...

```{r}
dirty_string = str_remove_all(dirty_string,"\\d")
dirty_string
```


Remove the odd punctuation.

```{r}
dirty_string = str_remove_all(dirty_string,"[:punct:]")
dirty_string
```

```{r}
dirty_string = str_remove_all(dirty_string,"\\$")
dirty_string
```


### Example 2

```{r}
dirty_text <-"

    A comedian with no political experience has won the most votes in the first round of Ukraine's presidential elections, according to exit polls.

They say Volodymyr Zelenskiy - who played the president on TV - received 30.4% of the vote, with current leader Petro Poroshenko second on 17.8%.

The two - who have expressed largely pro-EU opinions - are set to take part in a run-off election next month.


"

dirty_text
```

Remove the excess white space

```{r}
dirty_text <- str_trim(dirty_text)
dirty_text
```

Remove the spacing in the middle of the text (`\n` = "return"/"new line")

```{r}
dirty_text <- str_remove_all(dirty_text,"\\n")
dirty_text
```

Let's remove the subordinate clauses.

```{r}
text_list <- str_split(dirty_text," - ")
text_list
```
```{r}
text_list <- text_list[[1]]
text_list <- text_list[c(-2,-4)]
text_list
```

```{r}
dirty_text <-  str_c(text_list,collapse = " ")
dirty_text
```

Add spaces between the sentences (but need to make sure we don't split up the percentages!)

```{r}
dirty_text <- str_replace_all(dirty_text,"\\.(?!\\d)",". ") 
dirty_text 
```



# Text as Data: Exploring Inaugural Presidential Speaches 

Read data in and clean.
```{r}
inaug_dat <- 
  read_csv("inaug_speeches.csv") 
head(inaug_dat)
```

Clean data.

```{r}
dat <- 
  inaug_dat %>% 
  transmute(president = str_to_lower(Name) %>% str_replace_all(.," ","_"),
            address = ifelse(str_detect(`Inaugural Address`,"First"),"first","second"),
            date = as.Date(Date,"%A, %B %d, %Y"),
            year = lubridate::year(date),
            length = str_count(text),
            text = text)

# Adjust for one problematic date
dat[dat$president=="bill_clinton" & dat$address=="second",]$date = as.Date("1997-01-20")
dat[dat$president=="bill_clinton" & dat$address=="second",]$year = 1997

head(dat)
```

Let's look at the length of speeches over time.

```{r}
dat %>% 
  ggplot(aes(year,length)) +
  geom_col()
```

Who was the most/least verbose?

```{r}
dat %>% 
  filter(max(length)==length) %>% 
  select(president,length)
```

```{r}
dat %>% 
  filter(min(length)==length) %>% 
  select(president,length)
```

Convert text to tidy format.

```{r}
text_dat <- 
  dat %>% 
  unnest_tokens(word,text) 

head(text_dat)
```

Remove stopwords and digits. 

```{r}
text_dat <- 
  text_dat %>% 
  anti_join(stop_words,by="word") %>% 
  filter(!str_detect(word,"\\d")) %>% 
  
  # From the TM package (must install if you don't have)
  mutate(word = tm::removePunctuation(word)) 
  

head(text_dat)
```

Count term frequencies.

```{r}
text_dat_freq <-
  text_dat %>% 
  group_by(president,address,year) %>% 
  count(word,sort=T) %>% 
  ungroup()
```


Top 25 most common words?

```{r}
text_dat_freq %>% 
  mutate(word = reorder(word,n)) %>% 
  slice(1:25) %>% 
  ggplot(aes(word,n)) +
  geom_col() +
  coord_flip()
```



Let's look at the top ten words by president. 

```{r,fig.align="center",fig.width=10,fig.height=30}
text_dat_freq %>% 
  group_by(president) %>% 
  top_n(10,n) %>% 
  ggplot(aes(word,n)) +
  geom_col() + 
  coord_flip() +
  facet_wrap(~president,scales = "free",ncol=3) +
  theme(text = element_text(size=18))
```



## Sentiment 

Let's examine the sentiment of the speeches.

```{r}
text_dat_sent <- 
  text_dat %>% 
  inner_join(get_sentiments("afinn"),by='word')

text_dat_sent
```


On Average, which president was "most postive"?

```{r}
text_dat_sent %>% 
  group_by(president,year,address) %>% 
  summarize(ave_score = mean(score)) %>% 
  ungroup %>% 
  filter(ave_score == max(ave_score))
```

The most negative?

```{r}
text_dat_sent %>% 
  group_by(president,year,address) %>% 
  summarize(ave_score = mean(score)) %>% 
  ungroup %>% 
  filter(ave_score == min(ave_score))
```

Let's examin the sentiment of the most recent Republican presidents. 

```{r,fig.align="center",fig.width=7,fig.height=8}
text_dat_sent %>% 
  filter(president %in% c("george_w._bush","donald_j._trump")) %>% 
  group_by(president,address) %>% 
  mutate(index = row_number()) %>% 
  ungroup %>% 
  mutate(id = str_glue("{president} ({address})"),
         classify = ifelse(score>0,"steelblue","orangered")) %>% 
  
  # Now plot
  ggplot(aes(index,score,fill=classify)) +
  geom_col(show.legend = F) +
  facet_wrap(~id,scales = "free_x",ncol=1) +
  scale_fill_identity() +
  theme_minimal() +
  theme(text = element_text(size=16))
```


Let's explore a different sentiment classifier and see if we get a similar story. Note that we'll do _everything_ all in one seamless pipeline. Recall that the `bing` sentiment classifier is binary ("positive"/"negative")

```{r,fig.align="center",fig.width=7,fig.height=4}

# First Classify
text_dat %>% 
  inner_join(get_sentiments("bing"),by='word') %>%
  
  
  # Next subset out the relevant presidents
  filter(president %in% c("george_w._bush","donald_j._trump")) %>% 
  group_by(president,address) %>% 
  mutate(index = row_number()) %>% 
  ungroup %>% 
  mutate(id = str_glue("{president} ({address})"),
         classify = ifelse(sentiment=="positive","steelblue","darkred")) %>% 
  
  # Now plot
  ggplot(aes(index,president,fill=classify)) +
  geom_tile(show.legend = F) +
  facet_wrap(~id,scales = "free",ncol=1) +
  scale_fill_identity() +
  labs(y="") +
  theme_minimal() +
  theme(text = element_text(size=16))
```

Looks largely the same...


## Topic Models 

Let's run a topic model on the last 30 years of inaugural speeches and explore the types of topics they covered.

Let's subset the text and convert to a document term matrix. 
```{r}
dtm <- 
  text_dat %>% 
  # filter(year >= 1989) %>% 
  mutate(id = str_glue("{president} ({address})")) %>% 
  group_by(id) %>% 
  count(word) %>% 
  ungroup %>% 
  cast_dtm(document = id,term = word,value = n) 

dtm
```

Let's run a topic model with 4 possible topics.

```{r}
inaug_lda <- LDA(dtm,k=2,control = list(seed = 1234))
```

Let's explore the topic output. 

What are the top ten words most associated with each topic?

```{r,fig.width=7,fig.height=4}
# Extract the term to topic associations
inaug_lda %>% 
  tidy(metric="beta") %>% 
  
  # Convert topics metrics to proportions
  group_by(topic) %>% 
  mutate(prop = beta/sum(beta)) %>% 
  
  # Grab the top 10
  top_n(10,prop) %>% 
  ungroup %>% 
  
  # Rename topic label
  mutate(topic_label = str_glue("Topic {topic}")) %>% 
  
  # Plot as word cloud
  ggplot(aes(label=term,size=prop)) +
  ggwordcloud::geom_text_wordcloud_area() + 
  scale_size_area(max_size = 15) +
  facet_wrap(~topic_label,scales="free",ncol=2) 
```

Can we associate meaning to these topics?


Let's associate presidents speeches to specific topic entries. We can easily reassociate our topic allocations with the words used to find which presidents were most associated with the two topics. 


```{r}
pres_topic_member <- tidy(inaug_lda,"gamma") %>% 
  mutate(gamma = round(gamma,3))
pres_topic_member
```

Let's now re-assign the years.

```{r}
year_key <- 
  text_dat %>% 
  mutate(document = str_glue("{president} ({address})") %>% as.character) %>% 
  select(document,year) %>% 
  unique()

year_key
```

Merge the two data sources and examine the change in topic membership over time...

```{r,fig.width=10,fig.height=5}
full_join(pres_topic_member,year_key,by = "document") %>% 
  mutate(topic = ifelse(topic==1,"Internal Focus","External Focus")) %>% 
  ggplot(aes(year,gamma,fill=topic)) +
  geom_col(position="stack") +
  ggthemes::scale_fill_colorblind() +
  ggthemes::theme_tufte() +
  labs(y="Proportion",x="Years") +
  theme(text=element_text(size=20))
```

